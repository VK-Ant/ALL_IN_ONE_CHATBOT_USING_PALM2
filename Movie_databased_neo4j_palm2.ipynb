{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "NN54lbuS3HGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15de0656-8fdc-4609-b23b-800cf677760f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai\n",
        "!pip install -q neo4j-driver\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "8PUiEtL_3Ir4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "import gradio as gr\n",
        "from neo4j import GraphDatabase\n",
        "import re"
      ],
      "metadata": {
        "id": "WCdMGXYmBGa1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Key"
      ],
      "metadata": {
        "id": "Ol9L6OsS3PUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "palm.configure(api_key = \"your api key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "yigAV2ji3e1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(input):\n",
        "\n",
        "    defaults = {\n",
        "  'model': 'models/text-bison-001',\n",
        "  'temperature': 0.7,\n",
        "  'candidate_count': 1,\n",
        "  'top_k': 40,\n",
        "  'top_p': 0.95,\n",
        "  'max_output_tokens': 1024,\n",
        "  'stop_sequences': [],\n",
        "  'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"You are an expert in converting English questions to Neo4j Cypher Graph code! The Graph has following Node Labels - Movie, Person and the Movie Node label has the following properties released, tagline, title and the Graph has the following Relationship types ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE!\n",
        "\n",
        "    All relationships ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE start from Person to Movie and not the other way around.\n",
        "\n",
        "    For example,\n",
        "    Example 1 - List down 5 movies that released after the year 2000, the Cypher command will be something like this\n",
        "    ``` MATCH (m:Movie)\n",
        "    WHERE m.released > 2000\n",
        "    RETURN m LIMIT 5\n",
        "    ```\n",
        "\n",
        "    Example 2 - Get all the people who acted in a movie that was released after 2010.\n",
        "    ```\n",
        "    MATCH (p:Person)-[r:ACTED_IN]-(m:Movie)\n",
        "    WHERE m.released > 2010\n",
        "    RETURN p,r,m\n",
        "    ```\n",
        "\n",
        "    Example 3 - Name the Director of the movie The Matrix Reloaded?\n",
        "    ```\n",
        "    MATCH (m:Movie)<-[:DIRECTED]-(p:Person)\n",
        "    WHERE m.title = 'Apollo 13'\n",
        "    RETURN p.name\n",
        "    ```\n",
        "\n",
        "    Dont include ``` and \\n in the output\n",
        "\n",
        "    {input}\"\"\"\n",
        "    response = palm.generate_text(**defaults, prompt=prompt)\n",
        "    return response.result"
      ],
      "metadata": {
        "id": "E4N28-caJeiE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cypher language is similar to sql query using to neo4j"
      ],
      "metadata": {
        "id": "cQvKFwFMf-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_answer(\"which year comes forest gump and who is hero? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O-A5EA7OQqwV",
        "outputId": "71e59296-97b2-4908-a937-8866058d0e34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"MATCH (m:Movie {title: 'Forest Gump'}) RETURN m.released, m.hero\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_query_and_return_key(input_query_result):\n",
        "    slash_n_pattern = r'[ \\n]+'\n",
        "    ret_pattern = r'RETURN\\s+(.*)'\n",
        "    replacement = ' '\n",
        "\n",
        "    cleaned_query = re.sub(slash_n_pattern, replacement, input_query_result)\n",
        "    if cleaned_query:\n",
        "        match = re.search(ret_pattern, cleaned_query)\n",
        "        if match:\n",
        "            extracted_string = match.group(1)\n",
        "        else:\n",
        "            extracted_string = \"\"\n",
        "    return cleaned_query, extracted_string"
      ],
      "metadata": {
        "id": "Q6-mzSI4J1TZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_names_with_ampersand(names):\n",
        "    if len(names) == 0:\n",
        "        return \"\"\n",
        "    elif len(names) == 1:\n",
        "        return names[0]\n",
        "    else:\n",
        "        formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
        "        return formatted_names"
      ],
      "metadata": {
        "id": "H94gYGQf3xbE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_on_neo4j(inp_query, inp_key):\n",
        "    out_list = []\n",
        "    with driver.session() as session:\n",
        "        result = session.run(inp_query)\n",
        "        for record in result:\n",
        "            out_list.append(record[inp_key])\n",
        "    driver.close()\n",
        "    if len(out_list) > 1:\n",
        "        return format_names_with_ampersand(out_list)\n",
        "    else:\n",
        "        return out_list[0]"
      ],
      "metadata": {
        "id": "M-UiTgxt3z4N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_exec_cypher(input_query):\n",
        "    gen_query, gen_key = extract_query_and_return_key(get_answer(input_query))\n",
        "    return run_cypher_on_neo4j(gen_query, gen_key)"
      ],
      "metadata": {
        "id": "XWZxrzid4n3k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = str(generate_and_exec_cypher(input))\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ],
      "metadata": {
        "id": "IJsSnkrF4zqQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Driver"
      ],
      "metadata": {
        "id": "rDKVGFYB5CEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver = GraphDatabase.driver(\"your bolt URL in neo4j\",\n",
        "                              auth=(\"your neo4j username\",\n",
        "                                    \"your neo4j password\"))"
      ],
      "metadata": {
        "id": "Ot_mEa4jJo3O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch Gradio Interface"
      ],
      "metadata": {
        "id": "DclDEcma7fCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn = chatbot,title=\"Movie database: Knowledge Graph using Palm2 and neo4j\",\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state']).launch(debug = True)"
      ],
      "metadata": {
        "id": "Q3vNUUZI4wl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d98f1c22-e4f5-47d5-d293-3f073922d4fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://a594e2391814d03e78.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a594e2391814d03e78.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-6d234cc3d37d>:3: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 528, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1908, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1485, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 808, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-11-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-10-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-9-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 528, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1908, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1485, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 808, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-11-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-10-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-9-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a594e2391814d03e78.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ba1LiTGw4woD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
